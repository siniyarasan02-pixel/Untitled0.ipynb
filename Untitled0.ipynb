{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhPCtrS173Km7STii+kZlA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siniyarasan02-pixel/Untitled0.ipynb/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        " # Added to fix LookupError: Resource punkt_tab not found\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# FIX: Do not remove negation words for sentiment analysis!\n",
        "stop_words = set(stopwords.words('english'))\n",
        "negation_words = {'not', 'no', 'never', 'nor', 'neither', 'none'}\n",
        "stop_words = stop_words - negation_words\n",
        "\n",
        "# -----------------------------\n",
        "# Expanded Training Data\n",
        "# -----------------------------\n",
        "texts = [\n",
        "    # Positive (Label: 1)\n",
        "    \"I am very happy\",\n",
        "    \"This is amazing\",\n",
        "    \"I love this product\",\n",
        "    \"You are doing great\",\n",
        "    \"I feel fantastic today\",\n",
        "    \"That was wonderful\",\n",
        "    \"This makes me smile\",\n",
        "    \"I am excited about this\",\n",
        "    \"Everything is awesome\",\n",
        "    \"I am proud of you\",\n",
        "\n",
        "    # Negative (Label: 0)\n",
        "    \"I am very sad\",\n",
        "    \"This is terrible\",\n",
        "    \"I hate this\",\n",
        "    \"I feel disappointed\",\n",
        "    \"This is the worst\",\n",
        "    \"I am upset\",\n",
        "    \"That was horrible\",\n",
        "    \"I feel angry\",\n",
        "    \"This makes me frustrated\",\n",
        "    \"I am not happy\"\n",
        "]\n",
        "\n",
        "labels = [1]*10 + [0]*10\n",
        "\n",
        "# -----------------------------\n",
        "# Preprocessing Function\n",
        "# -----------------------------\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = word_tokenize(text)\n",
        "    # Filter stopwords but keep negations\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "processed_texts = [preprocess(t) for t in texts]\n",
        "\n",
        "# -----------------------------\n",
        "# TF-IDF + Model Training\n",
        "# -----------------------------\n",
        "# Added ngram_range to catch \"not happy\" as a single unit\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "X = vectorizer.fit_transform(processed_texts)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X, labels)\n",
        "\n",
        "print(\"ðŸ¤– Chatbot Ready! Type 'exit' to stop.\\n\")\n",
        "\n",
        "# -----------------------------\n",
        "# Interactive Chat Loop\n",
        "# -----------------------------\n",
        "while True:\n",
        "    user_input = input(\"You: \").strip()\n",
        "\n",
        "    if not user_input:\n",
        "        continue\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Chatbot: Goodbye! ðŸ‘‹\")\n",
        "        break\n",
        "\n",
        "    processed_input = preprocess(user_input)\n",
        "\n",
        "    # Check if preprocessing left us with an empty string\n",
        "    if not processed_input:\n",
        "        print(\"Chatbot: I'm not sure how to feel about that.\")\n",
        "        continue\n",
        "\n",
        "    input_vector = vectorizer.transform([processed_input])\n",
        "    prediction = model.predict(input_vector)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        print(\"Chatbot: ðŸ˜Š You sound positive!\")\n",
        "    else:\n",
        "        print(\"Chatbot: ðŸ˜” You seem upset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi2Dwzt57YUU",
        "outputId": "ff275e41-5e6c-4302-b627-f40e1bd5f19e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¤– Chatbot Ready! Type 'exit' to stop.\n",
            "\n",
            "Chatbot: ðŸ˜Š You sound positive!\n",
            "Chatbot: ðŸ˜” You seem upset.\n",
            "You: exit\n",
            "Chatbot: Goodbye! ðŸ‘‹\n"
          ]
        }
      ]
    }
  ]
}